{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QZjx03reMU5"
   },
   "source": [
    "#Import the required libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jddSFp3j_hAs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA, RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUCYUMnLgvJ5"
   },
   "source": [
    "# Loading Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9S0HlZhW_ofN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split documents: 20\n",
      "Chunk 1: that goes beyond the traditional aspects of \n",
      "collective bargaining in order to share knowledge \n",
      "and to jointly find opportunities related to \n",
      "important matters such as Creating Shared Value, \n",
      "the heal...\n",
      "Chunk 2: minimal levels of management and broad spans \n",
      "of control, which enable people development, \n",
      "increase efficiency, and ease implementation \n",
      "of our “Nestlé Management and Leadership \n",
      "Principles”.\n",
      "Less hi...\n",
      "Chunk 3: A dynamic organisation creates a climate \n",
      "of innovation and allows people to think from \n",
      "different perspectives. At Nestlé we encourage \n",
      "our people to take risks. Mistakes may be made \n",
      "but there is al...\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader('https://www.nestle.com/sites/default/files/asset-library/documents/jobs/the_nestle_hr_policy_pdf_2012.pdf')\n",
    "documents = loader.load()\n",
    "\n",
    "# initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # Maximum size of each chunk\n",
    "    chunk_overlap=200 # Overlap between chunks to preserve context\n",
    ")\n",
    "\n",
    "# Split the loaded documents\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# verify the split documents\n",
    "print(f\"Number of split documents: {len(split_documents)}\")\n",
    "# preview the last 3 chunks\n",
    "for i, doc in enumerate(split_documents[-3:]):  # Preview last 3 chunks\n",
    "    print(f\"Chunk {i+1}: {doc.page_content[:200]}...\")  # Print first 200 characters of each chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH5NQqp_in_T"
   },
   "source": [
    " # Creating Vector Representation of Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5bY_6TK_yFC",
    "outputId": "b509cdcd-f683-474d-fe5b-e9a253f9ba99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abibou\\AppData\\Local\\Temp\\ipykernel_9572\\2926562203.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# number of chunks for cheaper embedding\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(texts, embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2CP1tCAiyTS"
   },
   "source": [
    "# Setting Up Question-Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JKMZGJeWi17S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When was the Nestlé HR Policy last updated?\n",
      "Answer: The Nestlé HR Policy was last updated in September 2012.\n"
     ]
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\"), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
    "query = \"When was the Nestlé HR Policy last updated?\"\n",
    "\n",
    "result = qa.invoke(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\", result['result'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVU8cmrSi6Da"
   },
   "source": [
    "# Defining Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M4CETG52_0yR"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define the prompt template in English\n",
    "template = \"\"\"\n",
    "I am a HR helpful assistant. Please answer the following question in English.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create the PromptTemplate instance with the modified English template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APP-VcVNjG6C"
   },
   "source": [
    "#  Building Chat Interface with Gradio and Launching the Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "OIPOs0CD_4G1",
    "outputId": "944a231d-3729-466f-d0c1-af33b50cecda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\gradio\\layouts\\column.py:59: UserWarning: 'scale' value should be an integer. Using 0.6 will cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://ead086e1db263f7fcf.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ead086e1db263f7fcf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abibou\\AppData\\Local\\Temp\\ipykernel_9572\\1580668044.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa.run(query)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "def add_text(history, text):\n",
    "    history = history + [{\"role\": \"user\", \"content\": text}]\n",
    "    return history, \"\"\n",
    "\n",
    "def bot(history):\n",
    "    query = history[-1][\"content\"]\n",
    "    query = prompt.format(question=query)\n",
    "    answer = qa.run(query)\n",
    "    # You can add source info if needed\n",
    "    history[-1][\"content\"] = answer\n",
    "    history[-1][\"role\"] = \"assistant\"\n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(\n",
    "        value=[],\n",
    "        elem_id=\"chatbot\",\n",
    "        type=\"messages\",\n",
    "        height=400\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=0.6):\n",
    "            txt = gr.Textbox(\n",
    "            show_label=False,\n",
    "            placeholder=\"Enter text and press enter\",\n",
    "            container=False\n",
    "        )\n",
    "\n",
    "    txt.submit(add_text, [chatbot, txt], [chatbot, txt]).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5EZK-XPCwxt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
